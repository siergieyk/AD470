{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Coyote or Dog\n## Table of Content:\n**1. [Project description](#section1)**\n\n**2. [Data acquisition](#section2)**\n* **2.1 [Package import](#section2.1)** \n* **2.2 [Change file names](#section2.2)**\n* **2.3 [Move files into dataset](#section2.3)** \n* **2.4 [Pull images](#section2.4)** \n\n**3. [Overfitting refinement](#section3)**\n* **3.1 [Pull three images from dogs & coyote](#section3.1)** \n* **3.2 [Standardize to same size](#section3.2)** \n* **3.3 [Create sub folders](#section3.3)** \n\n**4. [Trained model](#section4)**\n* **4.1 [Dropout Regularization](#section4.1)** \n* **4.2 [Image Data Augmentation](#section4.2)** \n* **4.3 [Transfer Learning](#section4.3)** \n\n**5. [Model validation](#section5)**\n* **5.1 [Final Dataset](#section5.1)** \n* **5.2 [Final model](#section5.2)** \n* **5.3 [Prediction](#section5.3)** "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# <b>Coyote or Dog</b>\n\n<b>1. Project description</b>\n<a id=\"section1\"></a>\n\nIn this assignemnt we used deep learning model that can accurately distinguish coyotes from dogs based on photos."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>2. Data acquisition</b>\n<a id=\"section2\"></a>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>2.1</b> Import packages\n<a id=\"section2.1\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os, sys\nimport shutil\n#module enables us to operate with file objects easily and without diving into file objects a lot\n\nfrom matplotlib import pyplot\nfrom matplotlib.image import imread\nfrom matplotlib import pyplot\n\nfrom os import listdir\nfrom os import makedirs\nfrom numpy import asarray\nfrom numpy import save\nimport tensorflow as tf\n\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.framework import device as tfdev\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.optimizers import SGD\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing.image import load_img\nfrom keras.models import load_model\nfrom keras.models import Model\n\nfrom shutil import copyfile\nfrom random import seed\nfrom random import random",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "\n<b>2.2</b> change file names to uniform names\n<a id=\"section2.2\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Retreive each file and rename file name to coyote.1.jpg, coyote.2.jpg...\nos.chdir('coyotes')\ni=1\nfor file in os.listdir():\n    src=file\n    dst=\"coyote.\"+str(i)+\".jpg\"\n    os.rename(src,dst)\n    i+=1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Retreive each file and rename file name to dog.1.jpg,dog.2.jpg...\nos.chdir('dogs')\ni=1\nfor file in os.listdir():\n    src=file\n    dst=\"dog.\"+str(i)+\".jpg\"\n    os.rename(src,dst)\n    i+=1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>2.3</b> Move files into folder dataset\n<a id=\"section2.3\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create new folder and move all dog files to new folder\nsource = 'dogs/'\ndestination = 'dataset_dogs_vs_coyotes/'\n\nfiles = os.listdir(source)\n\nfor f in files:\n    shutil.move(source+f, destination)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create new folder and move all coyote files to new folder\nsource = 'coyotes/'\ndestination = 'dataset_dogs_vs_coyotes/'\n\nfiles = os.listdir(source)\n\nfor f in files:\n    shutil.move(source+f, destination)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>3. Overfitting refinement</b>\n<a id=\"section3\"></a>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>3.1</b> Pull three images from dogs & coyote\n<a id=\"section3.1\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# retreive and display 3 test images from new folder   \nfolder = 'dataset_dogs_vs_coyotes/'\nfor i in range(1,4):\n    pyplot.subplot(330 + 1 + i)\n    filename = folder + 'dog.' + str(i) + '.jpg'\n    image = imread(filename)\n    pyplot.imshow(image)\n    pyplot.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# retreive and display 3 test images from new folder\nfolder = 'dataset_dogs_vs_coyotes/'\nfor i in range(1,4):\n    #Add a subplot to the current figure.\n    pyplot.subplot(330 + 1 + i)\n    filename = folder + 'coyote.' + str(i) + '.jpg'\n    image = imread(filename)\n    pyplot.imshow(image)\n    pyplot.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>3.2</b> Standardize to same size\n<a id=\"section3.2\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nfolder = 'dataset_dogs_vs_coyotes/'\nphotos, labels = list(), list()\n# enumerate files in the directory\nfor file in listdir(folder):\n    # determine class\n    output = 0.0\n    # check whether string starts with str\n    if file.startswith('coyote'):\n        output = 1.0\n        # load image\n    photo = load_img(folder + file, target_size=(200, 200))\n        # convert to numpy array\n    photo = img_to_array(photo)\n        # store\n    photos.append(photo)\n    labels.append(output)\n        # convert to a numpy arrays\nphotos = asarray(photos)\nlabels = asarray(labels)\nprint(photos.shape, labels.shape)\n# save the reshaped photos\nsave('dogs_vs_coyotes_photos.npy', photos)\nsave('dogs_vs_coyotes_labels.npy', labels)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Each file in dataset_dogs_vs_coyotes is observed and set aside if determined to be dog\nfolder = 'dataset_dogs_vs_coyotes/'\nphotos, labels = list(), list()\n\n#going through files in the dates directory\nfor file in listdir(folder):\n    \n\n    # if it's a dog, then oitput is 1, else 0\n    output = 0.0\n    if file.startswith('dog'):\n        output = 1.0\n\n        # load image size 200px over 200px\n    photo = load_img(folder + file, target_size=(200, 200))\n\n    # convert to numpy array\n    photo = img_to_array(photo)\n\n    # store\n    photos.append(photo)\n    labels.append(output)\n\n# convert to an arrays\nphotos = asarray(photos)\nlabels = asarray(labels)\nprint(photos.shape, labels.shape)\n\n# save the reshaped photos\nsave('dogs_vs_coyotes_photos.npy', photos)\nsave('dogs_vs_coyotes_labels.npy', labels)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from numpy import load",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "photos = load('dogs_vs_coyotes_photos.npy')\nlabels = load('dogs_vs_coyotes_labels.npy')\nprint(photos.shape, labels.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>3.3</b> Create sub folders\n<a id=\"section3.3\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create sub categories in order to train our model\n#random number generator\nseed(1)\n\n#% of pictures used for validation\nval_ratio = 0.3\n\n# move images into subdirectories\nsrc_directory = 'dataset_dogs_vs_coyotes'\n\n# we will train and test dogs and coyotes and then move them to their subfolders\nfor file in listdir(src_directory):\n    src = src_directory + '/' + file\n    dst_dir = 'train/'\n    if random() < val_ratio:\n        dst_dir = 'test/'\n    if file.startswith('coyote'):\n        dst = src_directory + '/' + dst_dir + 'coyotes/'  + file\n        copyfile(src, dst)\n    elif file.startswith('dog'):\n        dst = src_directory + '/' + dst_dir + 'dogs/'  + file\n        copyfile(src, dst)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>4. Trained model</b>\n<a id=\"section4\"></a>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>4.1</b> Dropout Regularization\n<a id=\"section4.1\"></a>"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# here we will start to train our model with the help of python libraries \n# the output will test our model and print the % of accuracy\n\n# define cnn model\ndef define_model():\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(1, activation='sigmoid'))\n\n    # compile model\n    opt = SGD(lr=0.001, momentum=0.9)\n    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n \n# plot diagnostic learning curves\ndef summarize_diagnostics(history):\n    # plot loss\n    pyplot.subplot(211)\n    pyplot.title('Cross Entropy Loss')\n    pyplot.plot(history.history['loss'], color='blue', label='train')\n    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n    # plot accuracy\n    pyplot.subplot(212)\n    pyplot.title('Classification Accuracy')\n    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n    # save plot to file\n    filename = sys.argv[0].split('/')[-1]\n    pyplot.savefig(filename + '_plot.png')\n    pyplot.close()\n \n#test harness for evaluating a model\ndef run_test_harness():\n\n    # define model\n    model = define_model()\n    \n\n    # create data generator\n    datagen = ImageDataGenerator(rescale=1.0/255.0)\n\n\n    # prepare iterators\n    train_it = datagen.flow_from_directory('dataset_dogs_vs_coyotes/train/',\n        class_mode='binary', batch_size=64, target_size=(200, 200))\n    test_it = datagen.flow_from_directory('dataset_dogs_vs_coyotes/test/',\n        class_mode='binary', batch_size=64, target_size=(200, 200))\n    # fit model\n    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n        validation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n    # evaluate model\n    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n    print('> %.3f' % (acc * 100.0))\n    # learning curves\n    summarize_diagnostics(history)\n\nrun_test_harness()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>4.2</b> Image Data Augmentation\n<a id=\"section4.2\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#if we do not have enough data or images, we augment images and data to give our machine the opportunity to learn\n#data generators\ntrain_datagen = ImageDataGenerator(rescale=1.0/255.0,\n    width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1.0/255.0)\n\n#data iterations\ntrain_it = train_datagen.flow_from_directory('dataset_dogs_vs_coyotes/train/',\n    class_mode='binary', batch_size=64, target_size=(200, 200))\ntest_it = test_datagen.flow_from_directory('dataset_dogs_vs_coyotes/test/',\n    class_mode='binary', batch_size=64, target_size=(200, 200))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#cnn model\ndef define_model():\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(1, activation='sigmoid'))\n    # compile model\n    opt = SGD(lr=0.001, momentum=0.9)\n    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\n#diagnostic learning curves\ndef summarize_diagnostics(history):\n    # plot loss\n    pyplot.subplot(211)\n    pyplot.title('Cross Entropy Loss')\n    pyplot.plot(history.history['loss'], color='blue', label='train')\n    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n    # plot accuracy\n    pyplot.subplot(212)\n    pyplot.title('Classification Accuracy')\n    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n    # save plot to file\n    filename = sys.argv[0].split('/')[-1]\n    pyplot.savefig(filename + '_plot.png')\n    pyplot.close()\n\n#test harness for evaluating a model\ndef run_test_harness():\n    # define model\n    model = define_model()\n    # create data generators\n    train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n        width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n    test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n    # prepare iterators\n    train_it = train_datagen.flow_from_directory('dataset_dogs_vs_coyotes/train/',\n        class_mode='binary', batch_size=64, target_size=(200, 200))\n    test_it = test_datagen.flow_from_directory('dataset_dogs_vs_coyotes/test/',\n        class_mode='binary', batch_size=64, target_size=(200, 200))\n    # fit model\n    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n        validation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)\n    # evaluate model\n    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n    print('> %.3f' % (acc * 100.0))\n    # learning curves\n    summarize_diagnostics(history)\n\n# entry point, run the test harness\nrun_test_harness()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>4.3</b> Transfer Learning\n<a id=\"section4.3\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# vgg16 model used for transfer learning on the dogs and cats dataset\n\n\n# define cnn model\ndef define_model():\n   \n    # load model\n    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n    # mark loaded layers as not trainable\n    for layer in model.layers:\n        layer.trainable = False\n    # add new classifier layers\n    flat1 = Flatten()(model.layers[-1].output)\n    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n    output = Dense(1, activation='sigmoid')(class1)\n    # define new model\n    model = Model(inputs=model.inputs, outputs=output)\n    # compile model\n    opt = SGD(lr=0.001, momentum=0.9)\n    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\n# plot diagnostic learning curves\ndef summarize_diagnostics(history):\n    # plot loss\n    pyplot.subplot(211)\n    pyplot.title('Cross Entropy Loss')\n    pyplot.plot(history.history['loss'], color='blue', label='train')\n    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n    # plot accuracy\n    pyplot.subplot(212)\n    pyplot.title('Classification Accuracy')\n    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n    # save plot to file\n    filename = sys.argv[0].split('/')[-1]\n    pyplot.savefig(filename + '_plot.png')\n    pyplot.close()\n\n# run the test harness for evaluating a model\ndef run_test_harness():\n    \n    # define model\n    model = define_model()\n   \n    # create data generator\n    datagen = ImageDataGenerator(featurewise_center=True)\n   \n    # specify imagenet mean values for centering\n    datagen.mean = [123.68, 116.779, 103.939]\n    # prepare iterator\n    train_it = datagen.flow_from_directory('dataset_dogs_vs_coyotes/train/',\n        class_mode='binary', batch_size=64, target_size=(224, 224))\n    test_it = datagen.flow_from_directory('dataset_dogs_vs_coyotes/test/',\n        class_mode='binary', batch_size=64, target_size=(224, 224))\n    # fit model\n    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n        validation_data=test_it, validation_steps=len(test_it), epochs=10, verbose=1)\n    # evaluate model\n    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n    print('> %.3f' % (acc * 100.0))\n    # learning curves\n    summarize_diagnostics(history)\n\n# entry point, run the test harness\nrun_test_harness()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>5. Model validation</b>\n<a id=\"section5\"></a>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>5.1</b> Final Dataset\n<a id=\"section5.1\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n\n#directories\ndataset_home = 'finalize_dogs_vs_coyotes/'\n# create label subdirectories and move files into it  \nlabeldirs = ['dogs/', 'coyotes/']\nfor labldir in labeldirs:\n    newdir = dataset_home + labldir\n    makedirs(newdir, exist_ok=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n# copy training dataset images into subdirectories\nsource = 'dataset_dogs_vs_coyotes/train/coyotes/'\ndestination = 'finalize_dogs_vs_coyotes/coyotes'\n\nfiles = os.listdir(source)\nfor f in files:\n    shutil.move(source+f, destination)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "source = 'dataset_dogs_vs_coyotes/train/dogs/'\ndestination = 'finalize_dogs_vs_coyotes/dogs'\n\nfiles = os.listdir(source)\nfor f in files:\n    shutil.move(source+f, destination)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>5.2</b> Final model\n<a id=\"section5.2\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# iterator\ndatagen = ImageDataGenerator(featurewise_center=True)\ntrain_it = datagen.flow_from_directory('finalize_dogs_vs_coyotes/',\n    class_mode='binary', batch_size=64, target_size=(224, 224))\n\n# model\nmodel = define_model()\nmodel.fit_generator(train_it, steps_per_epoch=len(train_it), epochs=10, verbose=0)\n\n# save model\nmodel.save('final_model.h5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# save the final model to file\n\n#cnn model\ndef define_model():\n    \n    # load model\n    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n    \n    # mark loaded layers as not trainable\n    for layer in model.layers:\n        layer.trainable = False\n    \n    # add new classifier layers\n    flat1 = Flatten()(model.layers[-1].output)\n    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n    output = Dense(1, activation='sigmoid')(class1)\n    \n    # define new model\n    model = Model(inputs=model.inputs, outputs=output)\n    \n    # compile model\n    opt = SGD(lr=0.001, momentum=0.9)\n    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n \n# Model evaluation a model\ndef run_test_harness():\n\n    # define model\n    model = define_model()\n    \n    datagen = ImageDataGenerator(featurewise_center=True)\n    \n    # specify imagenet mean values for centering\n    datagen.mean = [123.68, 116.779, 103.939]\n    \n    # prepare iterator\n    train_it = datagen.flow_from_directory('finalize_dogs_vs_coyotes/',\n        class_mode='binary', batch_size=64, target_size=(224, 224))\n    # fit model\n    model.fit_generator(train_it, steps_per_epoch=len(train_it), epochs=10, verbose=0)\n    # save model\n    model.save('final_model.h5')\n \n# entry point, run the test harness\nrun_test_harness()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b>5.3</b> Prediction\n<a id=\"section5.3\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# make a prediction for a new image.\n\n# load and prepare the image\ndef load_image(filename):\n    # load the image\n    img = load_img(filename, target_size=(224, 224))\n    # convert to array\n    img = img_to_array(img)\n    # reshape into a single sample with 3 channels\n    img = img.reshape(1, 224, 224, 3)\n    # center pixel data\n    img = img.astype('float32')\n    img = img - [123.68, 116.779, 103.939]\n    return img\n\n# load an image and predict the class\ndef run_example():\n    # load the image\n    img = load_image('1 (5).jpg')\n    # load model\n    model = load_model('final_model.h5')\n    # predict the class\n    result = model.predict(img)\n    print(result[0])\n    if result[0]==1:\n        print('Dog')\n    else:\n        print('Coyote')\n    \n# entry point, run the example\nrun_example()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}